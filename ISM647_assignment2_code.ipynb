{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISM 647 Assignment 2: \n",
    "## Cognitive Computing and Artificial Intelligence Application Development and Tutorial\n",
    "\n",
    "### Group Members: Yanan Liu, Indu Thiyagarajan, Shivani Goverdhan, and Vijayalakshmi E. C. Gari\n",
    "\n",
    "This application shows you how to use the cognitive services [Face API](https://azure.microsoft.com/services/cognitive-services/face/) from Microsoft Azure to detect faces in an image. The API also returns various attributes such as the gender and age of each person. The sample images used in this application are from the [How-Old Robot](http://www.how-old.net) that uses the same APIs.\n",
    "\n",
    "### How to run this application\n",
    "A valid subscription key and endpoint url (achieved by our group member) are provided in this application. So no prerequisites is needed to run this application. You can try with the default image url or use your own image url.\n",
    "\n",
    "To run this application step by step, click the \"Run\" button above in each cell with proper input(i.e., image url).\n",
    "\n",
    "To run this whole application, click \"Restart & Run All\" under the kernel option above.\n",
    "\n",
    "To clear the output and restart the application, click \"Restart & Clear Output\" under the kernel option above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: assert valid subscription key and endpoint url;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = '6851331e1f814eccae1f4b0c2fff7406'\n",
    "assert subscription_key\n",
    "\n",
    "face_api_url = 'https://eastus.api.cognitive.microsoft.com/face/v1.0/detect'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Import python library for functions will be used in this application and initialize parameters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "headers = { 'Ocp-Apim-Subscription-Key': subscription_key }\n",
    "    \n",
    "params = {\n",
    "    'returnFaceId': 'true',\n",
    "    'returnFaceLandmarks': 'false',\n",
    "    'returnFaceAttributes': 'age,gender,headPose,smile,facialHair,glasses,emotion,hair,makeup,occlusion,accessories,blur,exposure,noise',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Define face detection function using the Face API in Microsoft Azure;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(image_url):\n",
    "    response = requests.post(face_api_url, params=params, headers=headers, json={\"url\": image_url})\n",
    "    faces = response.json()\n",
    "\n",
    "    image_file = BytesIO(requests.get(image_url).content)\n",
    "    image = Image.open(image_file)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ax = plt.imshow(image, alpha=0.6)\n",
    "    for face in faces:\n",
    "        fr = face[\"faceRectangle\"]\n",
    "        fa = face[\"faceAttributes\"]\n",
    "        origin = (fr[\"left\"], fr[\"top\"])\n",
    "        p = patches.Rectangle(origin, fr[\"width\"], \\\n",
    "                              fr[\"height\"], fill=False, linewidth=2, color='b')\n",
    "        ax.axes.add_patch(p)\n",
    "        plt.text(origin[0], origin[1], \"%s, %d\"%(fa[\"gender\"].capitalize(), fa[\"age\"]), \\\n",
    "                 fontsize=12, weight=\"bold\", color='r', va=\"bottom\")\n",
    "    plt.axis(\"off\")\n",
    "    return(HTML(\"<font size=5>Detected <font color='blue'>%d</font> faces in this image</font>\"%len(faces)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Have fun with the images you provided! (Simply replace the url with the image url you want to test) :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection(\"https://how-old.net/Images/faces2/main006.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
